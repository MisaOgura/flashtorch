{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize image-specific class saliency with backpropagation\n",
    "\n",
    "---\n",
    "\n",
    "A quick demo of creating saliency maps for CNNs using [FlashTorch üî¶](https://github.com/MisaOgura/flashtorch).\n",
    "\n",
    "\n",
    "‚ùóThis notebook is for those who are using this notebook in **Google Colab**.\n",
    "\n",
    "If you aren't on Google Colab already, please head to the Colab version of this notebook **[here](https://colab.research.google.com/github/MisaOgura/flashtorch/blob/master/examples/visualise_saliency_with_backprop_colab.ipynb)** to execute.\n",
    "\n",
    "---\n",
    "\n",
    "The gradients obtained can be used to visualise an image-specific class saliency map, which can gives some intuition on regions within the input image that contribute the most (and least) to the corresponding output.\n",
    "\n",
    "More details on saliency maps: [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://arxiv.org/pdf/1312.6034.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install flashtorch\n",
    "\n",
    "!pip install flashtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the example image\n",
    "\n",
    "!mkdir -p images\n",
    "\n",
    "!wget https://github.com/MisaOgura/flashtorch/raw/master/examples/images/great_grey_owl.jpg -P /content/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from flashtorch.utils import (apply_transforms,\n",
    "                              denormalize,\n",
    "                              format_for_plotting,\n",
    "                              load_image,\n",
    "                              visualize)\n",
    "\n",
    "from flashtorch.utils import ImageNetIndex\n",
    "\n",
    "from flashtorch.saliency import Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image('/content/images/great_grey_owl.jpg')\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title('Original image')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load a pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create an instance of Backprop with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop = Backprop(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the gradients of a target class w.r.t the input image\n",
    "\n",
    "By default, we return the gradients of all the colour channel.\n",
    "\n",
    "You can also specify to return a max gradients across the colour channel via `take_max=True` flag, as this was what the authors did in the [paper](https://arxiv.org/pdf/1312.6034.pdf) and sometimes it renders better for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet = ImageNetIndex()\n",
    "target_class = imagenet['great grey owl']\n",
    "\n",
    "input_ = apply_transforms(image)\n",
    "\n",
    "# Calculate the gradients of each pixel w.r.t. the input image\n",
    "\n",
    "gradients = backprop.calculate_gradients(input_, target_class)\n",
    "\n",
    "# Or, take the maximum of the gradients for each pixel across colour channels.\n",
    "\n",
    "max_gradients = backprop.calculate_gradients(input_, target_class, take_max=True)\n",
    "\n",
    "print('Shape of the gradients:', gradients.shape)\n",
    "print('Shape of the max gradients:', max_gradients.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize the input image and gradients side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop.visualize(input_, target_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualize with _guided_ backprogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop.visualize(input_, target_class, guided=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
