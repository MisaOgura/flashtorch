{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation maximization\n",
    "\n",
    "---\n",
    "\n",
    "A quick demo of activation maximization with [FlashTorch üî¶](https://github.com/MisaOgura/flashtorch), using the pre-trained VGG16 model.\n",
    "\n",
    "\n",
    "‚ùóThis notebook is for those who are using this notebook in **Google Colab**.\n",
    "\n",
    "If you aren't on Google Colab already, please head to the Colab version of this notebook **[here](https://colab.research.google.com/github/MisaOgura/flashtorch/blob/master/examples/activation_maximization_colab.ipynb)** to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install flashtorch if you don't have it\n",
    "\n",
    "# !pip install flashtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "from flashtorch.activemax import GradientAscent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load a pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Print layers and corresponding indicies\n",
    "\n",
    "list(model.features.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify layers and filters\n",
    "\n",
    "conv1_2 = model.features[2]\n",
    "conv1_2_filters = [17, 33, 34, 57]\n",
    "\n",
    "conv2_1 = model.features[5]\n",
    "conv2_1_filters = [27, 40, 68, 73]\n",
    "\n",
    "conv3_1 = model.features[10]\n",
    "conv3_1_filters = [31, 61, 147, 182]\n",
    "\n",
    "conv4_1 = model.features[17]\n",
    "conv4_1_filters = [238, 251, 338, 495]\n",
    "\n",
    "conv5_1 = model.features[24]\n",
    "conv5_1_filters = [45, 271, 363, 409]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimize and visualize filters\n",
    "\n",
    "Creating an instance of `GradientAscent` class with the model _without fully-connected layers_ allows us to use flexible input image sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ascent = GradientAscent(model.features)\n",
    "\n",
    "g_ascent.visualize(conv1_2, conv1_2_filters, title='conv1_2');\n",
    "g_ascent.visualize(conv2_1, conv2_1_filters, title='conv2_1');\n",
    "g_ascent.visualize(conv3_1, conv3_1_filters, title='conv3_1');\n",
    "g_ascent.visualize(conv4_1, conv4_1_filters, title='conv4_1');\n",
    "g_ascent.visualize(conv5_1, conv5_1_filters, title='conv5_1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Other ways to optimize & visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. `visualize`: randomly select filters\n",
    "\n",
    "If you have a convolutional layer you want to vizualise, but you don't know which filters to choose, you can just pass in the layer to `visualize` without `filter_idxs`. It will randomly choose filters. You can adjust the number of filters chosen by passing `num_subplots` (default=4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ascent.visualize(conv5_1, title='Randomly selected filters from conv5_1');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. `visualize`: plot one filter\n",
    "\n",
    "If you just want to visualize one filter, you can do so by specifying the filter index as an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ascent.visualize(conv5_1, 3, title='conv5_1 filter 3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-3. `visualize`: when you need the optimized image tensor\n",
    "\n",
    "If you want to grab the optimized image data, set `return_output` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = g_ascent.visualize(conv5_1, 3, title='conv5_1 filter 3', return_output=True);\n",
    "\n",
    "print('num_iter:', len(output))\n",
    "print('optimized image:', output[-1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-4. `optimize`: when no visualization is needed\n",
    "\n",
    "If no visualization is needed, you can call the `optimize` method directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = g_ascent.optimize(conv5_1, 3)\n",
    "\n",
    "print('num_iter:', len(output))\n",
    "print('optimized image:', output[-1].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda:flashtorch",
   "language": "python",
   "name": "flashtorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
