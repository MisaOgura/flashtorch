{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise image-specific class saliency with backpropagation\n",
    "\n",
    "---\n",
    "A quick demo of creating saliency maps for CNNs using [FlashTorch üî¶](https://github.com/MisaOgura/flashtorch).\n",
    "\n",
    "\n",
    "‚ùóThis notebook is for those who are using this notebook in **Google Colab**.\n",
    "\n",
    "If you aren't on Google Colab already, please head to the Colab version of this notebook **[here](https://colab.research.google.com/github/MisaOgura/flashtorch/blob/master/examples/visualise_saliency_with_backprop_colab.ipynb)** to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install flashtorch\n",
    "\n",
    "!pip install flashtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the example image\n",
    "\n",
    "!mkdir -p images\n",
    "\n",
    "!wget https://github.com/MisaOgura/flashtorch/raw/master/examples/images/great_grey_owl.jpg -P /content/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "from flashtorch.utils import (apply_transforms,\n",
    "                              denormalize,\n",
    "                              format_for_plotting,\n",
    "                              load_image,\n",
    "                              visualize)\n",
    "\n",
    "from flashtorch.utils import ImageNetIndex\n",
    "\n",
    "from flashtorch.saliency import Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image('/content/images/great_grey_owl.jpg')\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.title('Original image')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load a pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create an instance of Backprop with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop = Backprop(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculate the gradients of a target class w.r.t the input image\n",
    "\n",
    "By default, we return the gradients of all the colour channel.\n",
    "\n",
    "You can also specify to return a max gradients across the colour channel via `take_max=True` flag, as this was what the authors did in the [paper](https://arxiv.org/pdf/1312.6034.pdf) and sometimes it renders better for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet = ImageNetIndex()\n",
    "target_class = imagenet['great grey owl']\n",
    "\n",
    "input_ = apply_transforms(image)\n",
    "\n",
    "# Calculate the gradients of each pixel w.r.t. the input image\n",
    "\n",
    "gradients = backprop.calculate_gradients(input_, target_class)\n",
    "\n",
    "# Or, take the maximum of the gradients for each pixel across colour channels.\n",
    "\n",
    "max_gradients = backprop.calculate_gradients(input_, target_class, take_max=True)\n",
    "\n",
    "print('Shape of the gradients:', gradients.shape)\n",
    "print('Shape of the max gradients:', max_gradients.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualise the input image and gradients side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(input_, gradients, max_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualise with _guided_ backprogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop = Backprop(model)\n",
    "\n",
    "guided_gradients = backprop.calculate_gradients(input_, target_class, guided=True)\n",
    "max_guided_gradients = backprop.calculate_gradients(input_, target_class, take_max=True, guided=True)\n",
    "\n",
    "visualize(input_, guided_gradients, max_guided_gradients, alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
